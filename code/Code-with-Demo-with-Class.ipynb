{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the code for generating the Python code representation of legal text by prompting GPT-4o with the class structure and demonstrations. The demonstrations are selected based on a strategy involving attribute overlap and cosine similarity as described in the paper. \n",
    "\n",
    "Please note that executing this notebook requires an OpenAI API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import random\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load development data\n",
    "df_train = pd.read_csv('path/to/train.csv') # Specify the correct path to your development data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the development set tag distribution     \n",
    "\n",
    "counter = Counter()\n",
    "for iter,d in df_train.iterrows():\n",
    "    tags = [d.strip()[1:-1] for d in d['tags'][1:-1].split(',')]\n",
    "    counter.update(tags)\n",
    "for tag, count in counter.most_common():\n",
    "    print(f\"{tag}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tags in development data to a list of strings\n",
    "df_train['tags'] = df_train['tags'].apply(lambda x: [d.strip()[1:-1] for d in x[1:-1].split(',')])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle the development data set with a fixed seed\n",
    "df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create k folds of the development data set\n",
    "k = 5\n",
    "folds = []\n",
    "\n",
    "for i in range(k):\n",
    "    folds.append(df_train[i::k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the folds in the development set folder\n",
    "for i, fold in enumerate(folds):\n",
    "    fold.to_csv(f'development_set/fold-{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For k fold setting\n",
    "\n",
    "# assign fold with index i as the testing set dataframe\n",
    "# assign all other folds as the development set dataframe\n",
    "\n",
    "index = 0 # Change this index to select different folds for testing\n",
    "df_test = folds[index]\n",
    "df_train = pd.concat(folds[:index] + folds[index+1:])\n",
    "\n",
    "print(f\"development set size: {len(df_train)}\")\n",
    "print(f\"Testing set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test file\n",
    "\n",
    "# read the testing set\n",
    "testing_set = pd.read_csv('path/to/test.csv')  # Specify the correct path to your testing data\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables for predefined tags\n",
    "\n",
    "predefined_tags = \"\"\"\n",
    "{\n",
    "    '#definition': 'a legal statement defining the meaning of concepts [mean, include]',\n",
    "    '#exclusion': 'a phrase highlighting what is excluded from the definition of a term [exclude, not include]',\n",
    "    '#exemption': 'a legal statement that exempts someone/something from a rule [exempt, does not apply to, does not require]',\n",
    "    '#obligation': 'a statement imposing mandatory action to be performed by an agent [shall, must]',\n",
    "    '#permission': 'a statement indicating the possibility to perform an action without an obligation or a prohibition [may, is permitted to, can, be deemed]',\n",
    "    '#prohibition': 'a statement forbidding an action to happen or take place [may not, shall not, must not]',\n",
    "    '#penalty': 'a statement indicating the punishment for not following a rule',\n",
    "    '#information': 'a legal statement about something that is known or proved to be true',\n",
    "    '#continuation': 'denoting nested legal statements; assigned whenever a phrase contains a colon and is followed by a bullet list',\n",
    "    '#condition': 'a phrase in a statement highlighting a constraint under which a rule applies [if, when, after]',\n",
    "    '#follows': 'relation that connects a statement to references or other statements that precede (act as pre-conditions to) the statement [pursuant to, in accordance with, under]',\n",
    "    '#refines': 'relation that connects a statement that provides more information about a reference or base statement to the reference or base statement',\n",
    "    '#followed_by': 'relation that connects a statement to references or other statements that follow the statement',\n",
    "    '#refined_by': 'relation that connects a base statement to a cross reference or another statement that provides more information about the base statement [as defined in, as described in]',\n",
    "    '#exception': 'relation that connects a statement to references or other expressions that are exceptions to the statement [unless, except]',\n",
    "    '#exception_to': 'relation that connects a statement that acts as a exception to a reference or base statement with the reference or base statement' [notwithstanding]\n",
    "    '#reference': 'when the text contains pointers, numbers, or names to other sections, paragraphs, or laws'\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "# Make sure to set your OpenAI API key in the environment variable OPENAI_API_KEY\n",
    "# Alternatively, you can pass the key directly to the OpenAI constructor with `api_key='your_api_key'`\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def prompt_model(prompt):\n",
    "    \"\"\"\n",
    "    Function to prompt the OpenAI model with a given prompt and return the response.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to send to the model.\n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "    # Call the OpenAI API to get a completion\n",
    "    # Ensure you have the correct model and parameters set\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        store=True,\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for the model\n",
    "\n",
    "prompt = \"\"\"Read the text and assign tags based on the definitions provided. Do not create your own tags. Only output the tags in the form of a python list. Do not include the assigned parts of the text in your response.\n",
    "\n",
    "Tag Definitions:\n",
    "%s\n",
    "\n",
    "Text: %s\n",
    "Tags: \"\"\"\n",
    "\n",
    "\n",
    "def exec_prompt(text):\n",
    "    \"\"\"\n",
    "    Function to execute the prompt with the given text and return the model's response.\n",
    "    Args:\n",
    "        text (str): The input text to analyze.\n",
    "    Returns:\n",
    "        str: The model's response containing the assigned tags.\n",
    "    \"\"\"\n",
    "    # Format the prompt with predefined tags and the input text\n",
    "    p = prompt % (predefined_tags, text)\n",
    "    # Call the model with the formatted prompt\n",
    "    a = prompt_model(p)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the model for each sample in the testing set and collect the answers\n",
    "\n",
    "print('Prompting for %i test samples' % len(testing_set), end='')\n",
    "answers = []\n",
    "for i in range(len(testing_set)):\n",
    "    # Execute the prompt for each text in the testing set\n",
    "    a = exec_prompt(testing_set.iloc[i]['text'])\n",
    "    answers.append(a)\n",
    "    print('. ', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(answer):\n",
    "    \"\"\"\n",
    "    Function to extract tags from the model's response.\n",
    "    Args:\n",
    "        answer (str): The model's response containing the tags.\n",
    "    Returns:\n",
    "        list: A list of unique tags extracted from the response.\n",
    "    \"\"\"\n",
    "    if answer[:10] == '```python\\n':\n",
    "        tags = answer[11:-5].split(',')\n",
    "    else:\n",
    "        tags = answer[1:-1].split(',')\n",
    "\n",
    "    tags = [tag.strip()[1:-1] for tag in tags]\n",
    "    return list(set(tags))\n",
    "\n",
    "# Extract tags from the model's answers and store them in the testing set\n",
    "testing_set['tags'] = [extract_tags(a) for a in answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for the development set\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    Function to compute the cosine similarity between two vectors.\n",
    "    Args:\n",
    "        v1 (list or np.array): First vector.\n",
    "        v2 (list or np.array): Second vector.\n",
    "    Returns:\n",
    "        float: Cosine similarity between the two vectors.\n",
    "    \"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "def select_demos(test_sample, demos, n=5):\n",
    "    \"\"\"\n",
    "    Function to select demonstrations based on the defined rules.\n",
    "    Args:\n",
    "        test_sample (dict): The test sample containing 'tags' and 'embedding'.\n",
    "        demos (list): List of demonstration samples, each containing 'tags' and 'embedding'.\n",
    "        n (int): Number of top demonstrations to return.\n",
    "    Returns:\n",
    "        list: Sorted list of demonstration samples based on the selection criteria.\n",
    "    \"\"\"\n",
    "    text_tags = set(test_sample['tags'])\n",
    "    # Find all demos that have at least one tag in common with the test sample\n",
    "    matches = []\n",
    "    for demo in demos:\n",
    "        demo_tags = set(demo['tags'])\n",
    "        overlap = text_tags.intersection(demo_tags)\n",
    "        if len(overlap) > 0:\n",
    "            matches.append([overlap, demo])\n",
    "\n",
    "    # Randomly shuffle the matches to ensure diversity in selection\n",
    "    random.shuffle(matches)\n",
    "\n",
    "    # Sort matches based on the number of overlapping tags and cosine similarity in descending order\n",
    "    matches.sort(\n",
    "        key=lambda x: (\n",
    "            len(x[0]),\n",
    "            cosine_similarity(test_sample['embedding'], x[1]['embedding'])\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    # Extract the sorted demos\n",
    "    sorted_demos = [m[1] for m in matches]\n",
    "\n",
    "    # Return top n (or fewer if not enough demos)\n",
    "    return sorted_demos[:n]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for the development set\n",
    "train_embeddings = []\n",
    "for i, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    # Embed the text using OpenAI embeddings\n",
    "    emb = embeddings.embed_query(text)\n",
    "    train_embeddings.append(emb)\n",
    "\n",
    "# Add the embeddings to the development set DataFrame\n",
    "df_train['embedding'] = train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for the testing set\n",
    "test_embeddings = []\n",
    "for i, row in testing_set.iterrows():\n",
    "    text = row['text']\n",
    "    # Embed the text using OpenAI embeddings\n",
    "    emb = embeddings.embed_query(text)\n",
    "    test_embeddings.append(emb)\n",
    "\n",
    "# Add the embeddings to the testing set DataFrame\n",
    "testing_set['embedding'] = test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert development_set to a list of dictionaries\n",
    "development_set = df_train.to_dict(orient='records')\n",
    "\n",
    "# convert testing_set to a list of dictionaries\n",
    "testing_set = testing_set.to_dict(orient='records')\n",
    "\n",
    "# Select demonstrations based on the testing set and development set, number of demos to select is set to 3\n",
    "demos = select_demos(testing_set[0], development_set, n=3)\n",
    "\n",
    "# If no demonstrations are selected, assign random demonstrations from the development set\n",
    "if len(demos) == 0:\n",
    "    # assign random demonstrations\n",
    "    demos = random.sample(development_set, 3)\n",
    "\n",
    "print('Demonstration Count: %i' % len(demos))\n",
    "print('Demonstration Tag Coverage: %s' % set([t for dem in demos for t in dem['tags']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting LLM to Generate the Code Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code string for the Section, Expression, Reference, Statement, Information, Definition, Rule, Exemption classes\n",
    "code_string = \"\"\" \n",
    "class Section:\n",
    "    \\\"\"\"\n",
    "    A bullet point in the legal text. Every bullet point starts a new Section,\n",
    "    and sub-bullet points become subSections.\n",
    "\n",
    "    Attributes:\n",
    "        sectionNumber (str): The identifying number or label of this Section.\n",
    "        sectionTitle (str): An optional title for this Section.\n",
    "        parent (Optional[Section]): The parent Section if this is a nested (sub-)Section,\n",
    "            otherwise None for a top-level Section.\n",
    "        subSections (List[Section]): Any child Sections nested under this Section.\n",
    "        expressions (List[Expression]): The Expression objects contained directly in this Section.\n",
    "        statements (List[Statement]): The Statement objects contained directly in this Section.\n",
    "\n",
    "    Methods:\n",
    "        add_subsection(subsection: 'Section'):\n",
    "            Adds a subsection (child) to this Section and sets the subsection's parent to self.\n",
    "\n",
    "        add_expression(expression: 'Expression'):\n",
    "            Adds an Expression object to this Section’s expressions list.\n",
    "\n",
    "        add_statement(statement: 'Statement'):\n",
    "            Adds a Statement object to this Section’s statements list.\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self,sectionNumber: str, sectionTitle: str = \"\", parent=None):\n",
    "        self.sectionNumber: str = sectionNumber\n",
    "        self.sectionTitle: str = sectionTitle\n",
    "        self.parent: Optional['Section'] = parent\n",
    "        self.subSections: List['Section'] = []\n",
    "        self.expressions: List['Expression'] = []\n",
    "        self.statements: List['Statement'] = []\n",
    "\n",
    "    def add_subsection(self, subsection: 'Section'):\n",
    "        self.subSections.append(subsection)\n",
    "        subsection.parent = self\n",
    "    def add_expression(self, expression: 'Expression'):\n",
    "        self.expressions.append(expression)\n",
    "    def add_statement(self, statement: 'Statement'):\n",
    "        self.statements.append(statement)\n",
    "\n",
    "\n",
    "class Expression:\n",
    "    \\\"\"\"\n",
    "    A snippet of text within one bullet point (Section). Represents the smallest\n",
    "    textual unit that can contain references in the text or other embedded elements.\n",
    "\n",
    "    Each Expression belongs to exactly one Section.\n",
    "\n",
    "    Attributes:\n",
    "        section (Section): The Section in which this Expression is found.\n",
    "        text (str): The textual content of the Expression.\n",
    "        includes (Optional[List[Expression]]): A child Expression in a subsection that this Expression includes\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self, section: Section, text: str, includes=None):\n",
    "        self.section: Section = section\n",
    "        section.add_expression(self)\n",
    "        self.text: str = text\n",
    "        self.includes: Optional[List[Expression]] = includes if includes is not None else []\n",
    "\n",
    "        \n",
    "class Reference(Expression):\n",
    "    \\\"\"\"\n",
    "    A type of Expression that refers to another part of the legal text.\n",
    "\n",
    "    Attributes:\n",
    "        target (Union[Expression, Statement]): The target Expression or Statement that this Reference points to.\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self, section: Section, text: str, target: Statement):\n",
    "        super().__init__(section, text)\n",
    "        self.target: Statement = target\n",
    "\n",
    "\n",
    "class Statement:\n",
    "    \\\"\"\"\n",
    "    A legal statement that can span multiple bullet points (Sections) if those\n",
    "    bullet points are nested under a single conceptual clause. Statements often\n",
    "    contain or refer to multiple Expressions.\n",
    "\n",
    "    Attributes:\n",
    "        section (Section): The Section that represents\n",
    "            the location in the text where this Statement starts.\n",
    "        relationships (dict of str -> List[Expression or Statement]): A dictionary of\n",
    "            six possible relationship types, each mapping to a list of Expressions or Statements\n",
    "            that are connected to this Statement or references that are present within the statement \n",
    "            in the specified manner.\n",
    "\n",
    "    Relationship keys:\n",
    "        - \"refines\": A list of References or Statements this Statement refines\n",
    "            (providing more detail about).\n",
    "        - \"is_refined_by\": A list of References or Statements that refine this Statement.\n",
    "        - \"has_exception\": A list of References or Statements that are exceptions to this Statement.\n",
    "        - \"is_exception_to\": A list of References or Statements for which this Statement is an exception.\n",
    "        - \"follows\": A list of References or Statements that precede (act as post-conditions to) this Statement.\n",
    "        - \"is_followed_by\": A list of References or Statements that follow this Statement.\n",
    "\n",
    "    Methods:\n",
    "        add_refines(target): Adds a target to the \"refines\" relationship.\n",
    "        add_exception(exception): Adds a target to the \"has_exception\" relationship.\n",
    "        add_follows(target): Adds a target to the \"follows\" relationship.\n",
    "        add_is_refined_by(target): Adds a target to the \"is_refined_by\" relationship.\n",
    "        add_is_exception_to(exception): Adds a target to the \"is_exception_to\" relationship.\n",
    "        add_is_followed_by(target): Adds a target to the \"is_followed_by\" relationship.\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self, section: Optional[Section] = None):\n",
    "        self.sections: Section = section\n",
    "        self.relationships = {\n",
    "            \"refines\": [],\n",
    "            \"is_refined_by\": [],\n",
    "            \"has_exception\": [],\n",
    "            \"is_exception_to\": [],\n",
    "            \"follows\": [],\n",
    "            \"is_followed_by\": []\n",
    "        }\n",
    "\n",
    "    def add_refines(self, target: Union['Reference', 'Statement']):\n",
    "        self.relationships[\"refines\"].append(target)\n",
    "    def add_exception(self, exception: Union['Reference', 'Statement']):\n",
    "        self.relationships[\"has_exception\"].append(exception)\n",
    "    def add_follows(self, target: Union['Reference', 'Statement']):\n",
    "        self.relationships[\"follows\"].append(target)\n",
    "    def add_is_refined_by(self, target: Union['Reference', 'Statement']):\n",
    "        self.relationships[\"is_refined_by\"].append(target)\n",
    "    def add_is_exception_to(self, exception: Union['Reference', 'Statement']):\n",
    "        self.relationships[\"is_exception_to\"].append(exception)\n",
    "    def add_is_followed_by(self, target: Union['Reference', 'Statement']):\n",
    "        self.relationships[\"is_followed_by\"].append(target)\n",
    "\n",
    "\n",
    "class Information(Statement):\n",
    "    \\\"\"\"\n",
    "    A type of Statement that represents something that is known or proved to be true.\n",
    "\n",
    "    Attributes:\n",
    "        description (List[Expression]): The Expressions that contains the factual information.\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self, section, description: Expression):\n",
    "        super().__init__(section)\n",
    "        self.description: List[Expression] = []\n",
    "        if description is not None:\n",
    "            self.description.append(description)\n",
    "\n",
    "\n",
    "class Definition(Statement):\n",
    "    \\\"\"\"\n",
    "    A type of Statement that defines a concept or term in the legal text.\n",
    "\n",
    "    Attributes:\n",
    "        defined_term (Expression): The Expression stating the term being defined.\n",
    "        meaning (List[Expression]): One or more Expressions elaborating the meaning of the term.\n",
    "        exclusions (List[Expression]): Expressions clarifying what the term excludes or does not cover.\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self, section, defined_term: Expression):\n",
    "        super().__init__(section)\n",
    "        self.defined_term: Expression = defined_term\n",
    "        self.meaning: List[Expression] = []\n",
    "        self.exclusions: List[Expression] = []\n",
    "\n",
    "\n",
    "class Rule(Statement):\n",
    "    \\\"\"\"\n",
    "    A Statement describing a legal rule, which may take one of four types: obligation,\n",
    "    permission, prohibition, or penalty.\n",
    "\n",
    "    Attributes:\n",
    "        rule_type (int): An integer indicating which type of rule. Should be one of:\n",
    "            OBLIGATION, PERMISSION, PROHIBITION, PENALTY.\n",
    "        entity (Expression): The main entity (person, object, etc.) to which the rule applies.\n",
    "        description (Expression): An Expression describing the rule.\n",
    "        conditions (List[Expression]): Expressions indicating the conditions under which the rule applies.\n",
    "    \\\"\"\"\n",
    "\n",
    "    OBLIGATION = 0\n",
    "    PERMISSION = 1\n",
    "    PROHIBITION = 2\n",
    "    PENALTY = 3\n",
    "\n",
    "    def __init__(self, section, entity: Expression):\n",
    "        super().__init__(section)\n",
    "        self.rule_type: int = None\n",
    "        self.entity: Expression = entity\n",
    "        self.description: Optional[Expression] = None\n",
    "        self.conditions: List[Expression] = []\n",
    "\n",
    "\n",
    "class Exemption(Statement):\n",
    "    \\\"\"\"\n",
    "    A type of Statement indicating that a person, object, or situation is exempt\n",
    "    from another rule or requirement.\n",
    "\n",
    "    Attributes:\n",
    "        description (List[Expression]): One or more Expressions describing the exemption.\n",
    "    \\\"\"\"\n",
    "\n",
    "    def __init__(self, section=None, description: Optional[Expression] = None):\n",
    "        super().__init__(section)\n",
    "        self.description: List[Expression] = []\n",
    "        if description is not None:\n",
    "            self.description.append(description)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for converting text to Python code using the class structure above\n",
    "prompt = \"\"\"Read the text and convert it to Python code. Use the class structure detailed below to write code. Do not create your own names. Examples have been provided. \n",
    "\n",
    "Class Structure:\n",
    "%s\n",
    "\n",
    "Examples: \n",
    "%s\n",
    "\n",
    "Text: %s\n",
    "Code: \"\"\"\n",
    "\n",
    "# Define the prompt for converting text to Python code using the class structure above\n",
    "prompt2 = \"\"\"Read the text and convert it to Python code. Examples have been provided. \n",
    "\n",
    "Examples: \n",
    "%s\n",
    "\n",
    "Text: %s\n",
    "Code: \"\"\"\n",
    "\n",
    "\n",
    "def exec_prompt(test_sample, development_set):\n",
    "    \"\"\"\n",
    "    Function to execute the prompt with the test sample and development set, returning the model's response.\n",
    "    Args:\n",
    "        test_sample (dict): The test sample containing 'text' and 'embedding'.\n",
    "        development_set (list): The development set containing demonstration samples.\n",
    "    Returns:\n",
    "        str: The model's response containing the generated Python code.\n",
    "    \"\"\"\n",
    "    # Select demonstrations based on the test sample and development set\n",
    "    demos = select_demos(test_sample, development_set, n=3)\n",
    "\n",
    "    # If no demonstrations are selected, assign random demonstrations from the development set\n",
    "    if len(demos) == 0:\n",
    "        demos = random.sample(development_set, 3)\n",
    "    \n",
    "    # Pass the code string and the selected demonstrations to the prompt\n",
    "    p = prompt % ('```python\\n' + code_string + '\\n```', '\\n\\n'.join(\n",
    "        ['Text: %s\\nCode: ```python\\n%s\\n```' % (d['text'], d['code']) for d in demos]), test_sample['text'])\n",
    "\n",
    "    # Call the model with the formatted prompt\n",
    "    a = prompt_model(p)\n",
    "\n",
    "    # Return the model's response\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of passes for the model to run\n",
    "passes = 3 # Change this value to set the number of passes\n",
    "\n",
    "# Execute the prompt for each test sample in the testing set for the specified number of passes\n",
    "for j in range(passes):\n",
    "    print('Pass %i' % (j + 1))\n",
    "    print('Prompting for %i test samples' % len(testing_set), end='')\n",
    "    answers = []\n",
    "    # For each test sample, execute the prompt and collect the answers\n",
    "    for t in testing_set:\n",
    "        a = exec_prompt(t, development_set)\n",
    "        answers.append(a)\n",
    "        print('. ', end='')\n",
    "    print()\n",
    "    # Assign the generated code to the corresponding test sample in the testing set\n",
    "    for i in range(len(testing_set)):\n",
    "        testing_set[i]['code'] = answers[i]\n",
    "    output_file = f'testing_set_pass_{j + 1}.csv' # Output file for each pass\n",
    "    try:\n",
    "        # Write the testing set with the generated code to a CSV file\n",
    "        with open(output_file, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['text', 'code', 'tags'])\n",
    "            for t in testing_set:\n",
    "                writer.writerow([t['text'], t['code'], t['tags']])\n",
    "        print(f'Wrote {output_file}')\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during file writing\n",
    "        print('Error writing file: ', e)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
